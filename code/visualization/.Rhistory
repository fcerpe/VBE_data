labels = c("controls - braille", "controls - scrambled", "experts - braille", "experts - scrambled")) +
scale_color_manual(values = c("control" = "#da5F49", "expert" = "#FF9E4A"), guide = "none") +
# Individual data clouds
geom_point(data = braille, aes(x = cluster,  y = activation),
alpha = 0.4) +
theme_classic() +
theme(axis.ticks = element_blank()) +
facet_grid(~factor(area, levels = c("VWFA", "lLO", "rLO", "V1", "lPosTemp")),
labeller = label_value) +
scale_x_discrete(labels = stats_braille$condition) +
labs(x = "Stimulus condition", y = "Mean univariate activation", title = "Univariate acitvation for BW and SBW")
ggplot(stats_braille, aes(x = cluster, y = mean_activation, fill = cluster, color = group)) +
geom_col(aes(x = cluster, y = mean_activation), position = "dodge", size = 1) +
geom_errorbar(aes(ymin = mean_activation - se_activation, ymax = mean_activation + se_activation), width = 0) +
scale_fill_manual(values = c("CI" = "#da5F49", "CS" = "#FFFFFF", "EI" = "#FF9E4A", "ES" = "#FFFFFF"),
labels = c("controls - braille", "controls - scrambled", "experts - braille", "experts - scrambled")) +
scale_color_manual(values = c("control" = "#da5F49", "expert" = "#FF9E4A"), guide = "none") +
# Individual data clouds
geom_point(data = braille, aes(x = cluster,  y = activation),
color = "gray",
alpha = 0.4) +
theme_classic() +
theme(axis.ticks = element_blank()) +
facet_grid(~factor(area, levels = c("VWFA", "lLO", "rLO", "V1", "lPosTemp")),
labeller = label_value) +
scale_x_discrete(labels = stats_braille$condition) +
labs(x = "Stimulus condition", y = "Mean univariate activation", title = "Univariate acitvation for BW and SBW")
ggplot(stats_braille, aes(x = cluster, y = mean_activation, fill = cluster, color = group)) +
geom_col(aes(x = cluster, y = mean_activation), position = "dodge", size = 1) +
geom_errorbar(aes(ymin = mean_activation - se_activation, ymax = mean_activation + se_activation), width = 0) +
scale_fill_manual(values = c("CI" = "#da5F49", "CS" = "#FFFFFF", "EI" = "#FF9E4A", "ES" = "#FFFFFF"),
labels = c("controls - braille", "controls - scrambled", "experts - braille", "experts - scrambled")) +
scale_color_manual(values = c("control" = "#da5F49", "expert" = "#FF9E4A"), guide = "none") +
# Individual data clouds
geom_point(data = braille, aes(x = cluster,  y = activation),
color = "#555555",
alpha = 0.4) +
theme_classic() +
theme(axis.ticks = element_blank()) +
facet_grid(~factor(area, levels = c("VWFA", "lLO", "rLO", "V1", "lPosTemp")),
labeller = label_value) +
scale_x_discrete(labels = stats_braille$condition) +
labs(x = "Stimulus condition", y = "Mean univariate activation", title = "Univariate acitvation for BW and SBW")
# Plot bars
# - with subject labels
ggplot(stats_braille, aes(x = cluster, y = mean_activation, fill = cluster, color = group)) +
geom_col(aes(x = cluster, y = mean_activation), position = "dodge", size = 1) +
geom_errorbar(aes(ymin = mean_activation - se_activation, ymax = mean_activation + se_activation), width = 0) +
scale_fill_manual(values = c("CI" = "#da5F49", "CS" = "#FFFFFF", "EI" = "#FF9E4A", "ES" = "#FFFFFF"),
labels = c("controls - braille", "controls - scrambled", "experts - braille", "experts - scrambled")) +
scale_color_manual(values = c("control" = "#da5F49", "expert" = "#FF9E4A"), guide = "none") +
# Individual data clouds
geom_point(data = braille, aes(x = cluster,  y = activation),
color = "#555555",
alpha = 0.4) +
theme_classic() +
theme(axis.ticks = element_blank()) +
facet_grid(~factor(area, levels = c("VWFA", "lLO", "rLO", "V1", "lPosTemp")),
labeller = label_value) +
scale_x_discrete(labels = stats_braille$condition) +
labs(x = "Stimulus condition", y = "Mean univariate activation", title = "Univariate acitvation for BW and SBW")
ggsave("figures/braille-selectivity_eyeMovements.png", width = 3000, height = 1800, dpi = 320, units = "px")
# Plot bars
# - with subject labels
ggplot(stats_braille, aes(x = cluster, y = mean_activation, fill = cluster, color = group)) +
geom_col(aes(x = cluster, y = mean_activation), position = "dodge", size = 1) +
geom_errorbar(aes(ymin = mean_activation - se_activation, ymax = mean_activation + se_activation), width = 0) +
scale_fill_manual(values = c("CI" = "#da5F49", "CS" = "#FFFFFF", "EI" = "#FF9E4A", "ES" = "#FFFFFF"),
labels = c("controls - braille", "controls - scrambled", "experts - braille", "experts - scrambled")) +
scale_color_manual(values = c("control" = "#da5F49", "expert" = "#FF9E4A"), guide = "none") +
# Individual data clouds
geom_point(data = braille, aes(x = cluster,  y = activation),
color = "#555555",
alpha = 0.4) +
theme_classic() +
theme(axis.ticks = element_blank()) +
facet_grid(~factor(area, levels = c("VWFA", "lLO", "rLO", "V1", "lPosTemp")),
labeller = label_value) +
scale_x_discrete(labels = stats_braille$condition) +
labs(x = "Stimulus condition", y = "Mean univariate activation", title = "Univariate acitvation for BW and SBW")
ggsave("../../outputs/derivatives/figures/braille-selectivity_eyeMovements.png", width = 3000, height = 1800, dpi = 320, units = "px")
ggsave("../../outputs/derivatives/figures/braille-selectivity_group-all_area-all_plot-eyeMovements.png", width = 3000, height = 1800, dpi = 320, units = "px")
# Add all necessary libraries
library("readxl")
library("tidyverse")
library("reshape2")
library("gridExtra")
library("pracma")
library("dplyr")
library("data.table")
library("ez")
v1 = read_csv('../mvpa/mvpa_stats/decoding-pairwise_modality-within_group-all_space-IXI549Space_rois-earlyVisual_nbvoxels-81.mat')
v1 = read_csv('../mvpa/mvpa_stats/decoding-pairwise_modality-within_group-all_space-IXI549Space_rois-earlyVisual_nbvoxels-81.csv')
# Add all necessary libraries
library("readxl")
library("tidyverse")
library("reshape2")
library("gridExtra")
library("pracma")
library("dplyr")
library("data.table")
library("ez")
v1 = read_csv('../mvpa/mvpa_stats/decoding-pairwise_modality-within_group-all_space-IXI549Space_rois-earlyVisual_nbvoxels-81.csv')
View(v1)
v1 <- read_csv('../mvpa/mvpa_stats/decoding-pairwise_modality-within_group-all_space-IXI549Space_rois-earlyVisual_nbvoxels-81.csv')
localized <- read_csv('../mvpa/mvpa_stats/decoding-pairwise_modality-within_group-all_space-IXI549Space_rois-expansion_nbvoxels-43.csv')
postemp <- read_csv('../mvpa/mvpa_stats/decoding-pairwise_modality-within_group-all_space-IXI549Space_rois-language_nbvoxels-62.csv')
View(v1)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
View(postemp_stats)
View(vwfa)
View(vwfa_stats)
View(vwfa)
View(vwfa)
vwfa[["decodingCondition"]]
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
vwfa[["decodingCondition"]]
vwfa <- pivot_wider(vwfa, names_from = decodingCondition, values_from = accuracy)
vwfa_wide <- pivot_wider(vwfa, names_from = decodingCondition, values_from = accuracy)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
# Re-arrange table to be inputed in JASP
# remove group indication
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
vwfa_wide <- pivot_wider(vwfa, names_from = decodingCondition, values_from = accuracy)
View(vwfa_wide)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
# Re-arrange table to be inputed in JASP
# remove group indication
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
data[c("subID", "accuracy", "decodingCondition")]
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
# Re-arrange table to be inputed in JASP
# remove group indication
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
data[c("subID", "accuracy", "decodingCondition")]
data[["subID", "accuracy", "decodingCondition"]]
vwfa[["subID", "accuracy", "decodingCondition"]]
vwfa[c("subID", "accuracy", "decodingCondition")]
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
# Re-arrange table to be inputed in JASP
# remove group indication
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
vwfa[c("subID", "accuracy", "decodingCondition")]
vwfa <- vwfapivot_wider(vwfa, names_from = decodingCondition, values_from = accuracy)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
# Re-arrange table to be inputed in JASP
# remove group indication
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
vwfa[c("subID", "accuracy", "decodingCondition")]
vwfa <- pivot_wider(vwfa, names_from = decodingCondition, values_from = accuracy)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Clean file: remove unnecessary lines, add information about group and script
v1 <- dataset_clean(v1)
loca <- dataset_clean(loca)
postemp <- dataset_clean(postemp)
# In the case of expansion, separate three ROIs
vwfa <- loca %>% filter(mask == 'VWFA')
llo <- loca %>% filter(mask == 'lLO')
rlo <- loca %>% filter(mask == 'rLO')
# Summarize information: mean of decoding accuracies
v1_stats <- dataset_stats(v1)
vwfa_stats <- dataset_stats(vwfa)
llo_stats <- dataset_stats(llo)
rlo_stats <- dataset_stats(rlo)
postemp_stats <- dataset_stats(postemp)
# Re-arrange table to be inputed in JASP
# remove group indication
vwfa$decodingCondition <- gsub("_exp|_ctr", "", vwfa$decodingCondition)
vwfa <- vwfa[c("subID", "accuracy", "decodingCondition")]
vwfa <- pivot_wider(vwfa, names_from = decodingCondition, values_from = accuracy)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
rearrange_table <- function(tableIn, area) {
# Clean file: remove unnecessary lines, add information about group and script
tableIn <- dataset_clean(tableIn)
# In the case of expansion, separate three ROIs
if(area == 'VWFA' || area == 'lLO' || area == 'rLO')
tableIn <- tableIn %>% filter(mask == area)
# remove group indication
tableIn$decodingCondition <- gsub("_exp|_ctr", "", tableIn$decodingCondition)
# Get subset of relevant columns
tableIn <- tableIn[c("subID", "accuracy", "decodingCondition")]
# Pivot table to make JASP happy
tableOut <- pivot_wider(tableOut, names_from = decodingCondition, values_from = accuracy)
# Add group column
tableOut <- tableOut %>% mutate(Group = ifelse(subID %in% c(6, 7, 8, 9, 12, 13), "experts", "novices"))
# Reorder the columns to have the new column in the second position
tableOut <- tableOut %>% select(subID, Group, everything())
}
vwfa <- rearrange_table(loca, 'VWFA')
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
rearrange_table <- function(tableIn, area) {
# Clean file: remove unnecessary lines, add information about group and script
tableIn <- dataset_clean(tableIn)
# In the case of expansion, separate three ROIs
if(area == 'VWFA' || area == 'lLO' || area == 'rLO')
tableIn <- tableIn %>% filter(mask == area)
# remove group indication
tableIn$decodingCondition <- gsub("_exp|_ctr", "", tableIn$decodingCondition)
# Get subset of relevant columns
tableIn <- tableIn[c("subID", "accuracy", "decodingCondition")]
# Pivot table to make JASP happy
tableOut <- pivot_wider(tableOut, names_from = decodingCondition, values_from = accuracy)
# Add group column
tableOut <- tableOut %>% mutate(Group = ifelse(subID %in% c(6, 7, 8, 9, 12, 13), "experts", "novices"))
# Reorder the columns to have the new column in the second position
tableOut <- tableOut %>% select(subID, Group, everything())
rearrange_table <- tableOut
}
vwfa <- rearrange_table(loca, 'VWFA')
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
rearrange_table <- function(tableIn, area) {
# Clean file: remove unnecessary lines, add information about group and script
tableIn <- dataset_clean(tableIn)
# In the case of expansion, separate three ROIs
if(area == 'VWFA' || area == 'lLO' || area == 'rLO')
tableIn <- tableIn %>% filter(mask == area)
# remove group indication
tableIn$decodingCondition <- gsub("_exp|_ctr", "", tableIn$decodingCondition)
# Get subset of relevant columns
tableIn <- tableIn[c("subID", "accuracy", "decodingCondition")]
# Pivot table to make JASP happy
tableOut <- pivot_wider(tableIn, names_from = decodingCondition, values_from = accuracy)
# Add group column
tableOut <- tableOut %>% mutate(Group = ifelse(subID %in% c(6, 7, 8, 9, 12, 13), "experts", "novices"))
# Reorder the columns to have the new column in the second position
tableOut <- tableOut %>% select(subID, Group, everything())
rearrange_table <- tableOut
}
vwfa <- rearrange_table(loca, 'VWFA')
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Call extraction for all the data
v1 <- rearrange_table(v1, 'V1')
vwfa <- rearrange_table(vwfa, 'VWFA')
View(v1)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
View(v1)
v1 <- rearrange_table(v1, 'V1')
vwfa <- rearrange_table(vwfa, 'VWFA')
View(v1)
View(postemp)
View(llo)
View(rlo)
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
v1 <- rearrange_table(v1, 'V1')
vwfa <- rearrange_table(vwfa, 'VWFA')
llo <- rearrange_table(llo, 'lLO')
postemp <- rearrange_table(postemp, 'PosTemp')
rlo <- rearrange_table(rlo, 'rLO')
tableIn <- vwfa
area <- 'VWFA'
tableIn <- dataset_clean(tableIn)
dataIn <- tableIn
View(dataIn)
# Add all necessary libraries
source("viz_supportFunctions.R")
# Load file
v1 <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'earlyVisual')
loca <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'expansion')
postemp <- dataset_import('pairwise', 'within', 'all', 'IXI549Space', 'language')
# Call extraction for all the data
v1 <- rearrange_table(v1, 'V1')
rearrange_table <- function(tableIn, area) {
# Clean file: remove unnecessary lines, add information about group and script
tableIn <- dataset_clean(tableIn)
# In the case of expansion, separate three ROIs
if(area == 'VWFA' || area == 'lLO' || area == 'rLO')
tableIn <- tableIn %>% filter(mask == area)
# remove group indication
tableIn$decodingCondition <- gsub("_exp|_ctr", "", tableIn$decodingCondition)
# Get subset of relevant columns
tableIn <- tableIn[c("subID", "accuracy", "decodingCondition")]
# Pivot table to make JASP happy
tableOut <- pivot_wider(tableIn, names_from = decodingCondition, values_from = accuracy)
# Add group column
tableOut <- tableOut %>% mutate(Group = ifelse(subID %in% c(6, 7, 8, 9, 12, 13), "experts", "novices"))
# Reorder the columns to have the new column in the second position
tableOut <- tableOut %>% select(subID, Group, everything())
rearrange_table <- tableOut
}
# Call extraction for all the data
v1 <- rearrange_table(v1, 'V1')
vwfa <- rearrange_table(loca, 'VWFA')
llo <- rearrange_table(loca, 'lLO')
rlo <- rearrange_table(loca, 'rLO')
postemp <- rearrange_table(postemp, 'PosTemp')
# Save all the data
write.csv(v1, '../mvpa/mvpa_stats/mvpa_area-V1_desc-jasp-compatible.csv', row.names = FALSE)
write.csv(vwfa, '../mvpa/mvpa_stats/mvpa_area-VWFA_desc-jasp-compatible.csv', row.names = FALSE)
write.csv(llo, '../mvpa/mvpa_stats/mvpa_area-lLO_desc-jasp-compatible.csv', row.names = FALSE)
write.csv(rlo, '../mvpa/mvpa_stats/mvpa_area-rLO_desc-jasp-compatible.csv', row.names = FALSE)
write.csv(postemp, '../mvpa/mvpa_stats/mvpa_area-PosTemp_desc-jasp-compatible.csv', row.names = FALSE)
# Peak activation
zscore <- c(5.09, 5.23, NA, 3.50, 4.23, 5.39)
# Cluster size
cluster <- c(113, 92, NA, 7, 37, 79)
# Expertise in years
years <- c(13, 1, 2, 5, 21, 5)
# Expertise in Words-per-minute (our reading list)
wpm <- c(23, 8, 11, 6, 10, 15)
corr_wpm_zscore = cor.test(wpm, zscore)
# and expertise in years of practice
# Peak activation
zscore <- c(5.09, 5.23, NA, 3.50, 4.23, 5.39)
# Cluster size
cluster <- c(113, 92, NA, 7, 37, 79)
# Expertise in years
years <- c(13, 1, 2, 5, 21, 5)
# Expertise in Words-per-minute (our reading list)
wpm <- c(23, 8, 11, 6, 10, 15)
# Correlations: each expertise measure with each univariate result
corr_wpm_zscore = cor.test(wpm, zscore)
corr_wpm_cluster = cor.test(wpm, cluster)
corr_years_zscore = cor.test(years, zscore)
corr_years_cluster = cor.test(years, zscore)
View(corr_wpm_cluster)
View(corr_wpm_zscore)
View(corr_years_zscore)
View(corr_years_cluster)
View(corr_wpm_cluster)
View(corr_wpm_cluster)
# Peak activation
zscore <- c(5.09, 5.23, 3.50, 4.23, 5.39)
# Cluster size
cluster <- c(113, 92, 7, 37, 79)
# Expertise in years
years <- c(13, 1, 5, 21, 5)
# Expertise in Words-per-minute (our reading list)
wpm <- c(23, 8, 6, 10, 15)
# Correlations: each expertise measure with each univariate result
corr_wpm_zscore = cor.test(wpm, zscore, )
corr_wpm_cluster = cor.test(wpm, cluster)
corr_years_zscore = cor.test(years, zscore)
corr_years_cluster = cor.test(years, zscore)
View(corr_wpm_zscore)
View(corr_wpm_cluster)
View(corr_years_cluster)
View(corr_years_zscore)
# Tentative correlation between univariate activation in the [BW > SBW] contrast
# and expertise in years of practice
# Peak activation
zscore <- c(5.09, 5.23, NA, 3.50, 4.23, 5.39)
# Cluster size
cluster <- c(113, 92, NA, 7, 37, 79)
# DICE overlap
dice <- c(51, 44, NA, 8, 34, 53)
# Expertise in years
years <- c(13, 1, 2, 5, 21, 5)
# Expertise in Words-per-minute (our reading list)
wpm <- c(23, 8, 11, 6, 10, 15)
# Correlations: each expertise measure with each univariate result
corr_wpm_zscore = cor.test(wpm, zscore)
corr_wpm_cluster = cor.test(wpm, cluster)
corr_wpm_dice = cor.test(wpm, dice)
corr_years_zscore = cor.test(years, zscore)
corr_years_cluster = cor.test(years, cluster)
corr_years_dice = cor.test(years, dice)
View(corr_wpm_cluster)
View(corr_wpm_dice)
View(corr_wpm_zscore)
View(corr_years_cluster)
View(corr_years_dice)
View(corr_years_zscore)
View(corr_wpm_dice)
View(corr_wpm_zscore)
View(corr_wpm_cluster)
